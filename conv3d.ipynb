{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“0.62.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1tuA4gHo2ZQ",
        "colab_type": "code",
        "outputId": "96b318c7-aa69-4059-d29e-c90336164dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgjSX_t6firm",
        "colab_type": "code",
        "outputId": "140740d4-e226-4c6f-f74b-ede8f560cd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections.abc import Sequence\n",
        "import random\n",
        "from pandas import DataFrame\n",
        "\n",
        "from mylib.utils.misc import rotation, reflection, crop, random_center, _triple\n",
        "filepath=\"/content/drive/My Drive/cnn/train_val.csv\"\n",
        "result=pd.read_csv('/content/drive/My Drive/cnn/sampleSubmission.csv')\n",
        "df=pd.read_csv(filepath,header=0,engine=\"python\")\n",
        "class Transform:\n",
        "    '''The online data augmentation, including:\n",
        "    1) random move the center by `move`\n",
        "    2) rotation 90 degrees increments\n",
        "    3) reflection in any axis\n",
        "    '''\n",
        "\n",
        "    def __init__(self, size, move):\n",
        "        self.size = _triple(size)\n",
        "        self.move = move\n",
        "\n",
        "    def __call__(self, arr, aux=None):\n",
        "        shape = arr.shape\n",
        "        if self.move is not None:\n",
        "            center = random_center(shape, self.move)\n",
        "            arr_ret = crop(arr, center, self.size)\n",
        "            angle = np.random.randint(4, size=3)\n",
        "            arr_ret = rotation(arr_ret, angle=angle)\n",
        "            axis = np.random.randint(4) - 1\n",
        "            arr_ret = reflection(arr_ret, axis=axis)\n",
        "            arr_ret = np.expand_dims(arr_ret, axis=-1)\n",
        "            if aux is not None:\n",
        "                aux_ret = crop(aux, center, self.size)\n",
        "                aux_ret = rotation(aux_ret, angle=angle)\n",
        "                aux_ret = reflection(aux_ret, axis=axis)\n",
        "                aux_ret = np.expand_dims(aux_ret, axis=-1)\n",
        "                return arr_ret, aux_ret\n",
        "            return arr_ret\n",
        "        else:\n",
        "            center = np.array(shape) // 2\n",
        "            arr_ret = crop(arr, center, self.size)\n",
        "            arr_ret = np.expand_dims(arr_ret, axis=-1)\n",
        "            if aux is not None:\n",
        "                aux_ret = crop(aux, center, self.size)\n",
        "                aux_ret = np.expand_dims(aux_ret, axis=-1)\n",
        "                return arr_ret, aux_ret\n",
        "            return arr_ret\n",
        "\n",
        "class ClfDataset(Sequence):\n",
        "    def __init__(self, crop_size=32, move=None):\n",
        "        self.transform = Transform(crop_size, move)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        name = df.loc[item, 'name']\n",
        "        with np.load(os.path.join('/content/drive/My Drive/cnn/train_val', '%s.npz' % name)) as npz:\n",
        "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\n",
        "        voxel=voxel*seg\n",
        "        label = df.loc[item, 'lable']\n",
        "        return voxel, (label,seg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return df._len_()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(data):\n",
        "        xs = []\n",
        "        ys = []\n",
        "        segs = []\n",
        "        for x, y in data:\n",
        "            xs.append(x)\n",
        "            ys.append(y[0])\n",
        "            segs.append(y[1])\n",
        "        return np.array(xs), {\"clf\": np.array(ys), \"seg\": np.array(segs)}\n",
        "\n",
        "class ClfDataset_test(Sequence):\n",
        "    def __init__(self, crop_size=32, move=None):\n",
        "        self.transform = Transform(crop_size,move)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        name = result.loc[item, 'name']\n",
        "        with np.load(os.path.join('/content/drive/My Drive/cnn/test', '%s.npz' % name)) as npz:\n",
        "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\n",
        "        voxel=voxel*seg\n",
        "        return voxel\n",
        "\n",
        "    def __len__(self):\n",
        "           \n",
        "        return df.__len__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(data):\n",
        "        xs = []\n",
        "        for x in data:\n",
        "            xs.append(x)\n",
        "        return np.array(xs)\n",
        "\n",
        "def get_loader_train(dataset, batch_size):\n",
        "    total_size = 415\n",
        "    print('Size', total_size)\n",
        "    index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for _ in range(batch_size):\n",
        "            idx = next(index_generator)\n",
        "            data.append(dataset[idx])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def get_loader_val(dataset, batch_size):\n",
        "    total_size = 50\n",
        "    print('Size', total_size)\n",
        "    index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for _ in range(batch_size):\n",
        "            idx = next(index_generator)\n",
        "            data.append(dataset[idx+415])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def get_loader_test(dataset, batch_size):\n",
        "    total_size = 117\n",
        "    print('Size', total_size)\n",
        "    #index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for i in range(batch_size):\n",
        "            #idx = next(index_generator)\n",
        "            idx=i\n",
        "            data.append(dataset[idx])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def shuffle_iterator(iterator):\n",
        "    # iterator should have limited size\n",
        "    index = list(iterator)\n",
        "    total_size = len(index)\n",
        "    i = 0\n",
        "    random.shuffle(index)\n",
        "    while True:\n",
        "        yield index[i]\n",
        "        i += 1\n",
        "        if i >= total_size:\n",
        "            i = 0\n",
        "            random.shuffle(index)\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "dataset = ClfDataset(crop_size=32)\n",
        "test_dataset = ClfDataset_test(crop_size=32)\n",
        "train_loader = get_loader_train(dataset, batch_size=30)\n",
        "val_loader = get_loader_val(dataset, batch_size=10)\n",
        "test_loader = get_loader_test(test_dataset, batch_size=117)\n",
        "crop_size=[32, 32, 32]\n",
        "random_move=3\n",
        "learning_rate=1.e-3\n",
        "segmentation_task_ratio=0.2\n",
        "weight_decay=0.\n",
        "save_folder='test'\n",
        "epochs=100\n",
        "\n",
        "\n",
        "from keras.layers import (Conv3D, BatchNormalization, AveragePooling3D, concatenate, Lambda, SpatialDropout3D,\n",
        "                          Activation, Input, GlobalAvgPool3D, Dense, Conv3DTranspose, add)\n",
        "from keras.regularizers import l2 as l2_penalty\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "PARAMS = {\n",
        "    'activation': lambda: Activation('relu'),  # the activation functions\n",
        "    'bn_scale': True,  # whether to use the scale function in BN\n",
        "    'weight_decay': 0.,  # l2 weight decay\n",
        "    'kernel_initializer': 'he_uniform',  # initialization\n",
        "    'first_scale': lambda x: x / 128. - 1.,  # the first pre-processing function\n",
        "    'dhw': [32, 32, 32],  # the input shape\n",
        "    'k': 16,  # the `growth rate` in DenseNet\n",
        "    'bottleneck': 4,  # the `bottleneck` in DenseNet\n",
        "    'compression': 2,  # the `compression` in DenseNet\n",
        "    'first_layer': 32,  # the channel of the first layer\n",
        "    'down_structure': [4, 4, 4],  # the down-sample structure\n",
        "    'output_size': 1,  # the output number of the classification head\n",
        "    'dropout_rate': None  # whether to use dropout, and how much to use\n",
        "}\n",
        "\n",
        "\n",
        "def _conv_block(x, filters):\n",
        "    bn_scale = PARAMS['bn_scale']\n",
        "    activation = PARAMS['activation']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    bottleneck = PARAMS['bottleneck']\n",
        "    dropout_rate = PARAMS['dropout_rate']\n",
        "\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    x = Conv3D(filters * bottleneck, kernel_size=(1, 1, 1), padding='same', use_bias=False,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "    if dropout_rate is not None:\n",
        "        x = SpatialDropout3D(dropout_rate)(x)\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    x = Conv3D(filters, kernel_size=(3, 3, 3), padding='same', use_bias=True,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _dense_block(x, n):\n",
        "    k = PARAMS['k']\n",
        "\n",
        "    for _ in range(n):\n",
        "        conv = _conv_block(x, k)\n",
        "        x = concatenate([conv, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _transmit_block(x, is_last):\n",
        "    bn_scale = PARAMS['bn_scale']\n",
        "    activation = PARAMS['activation']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    compression = PARAMS['compression']\n",
        "\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    if is_last:\n",
        "        x = GlobalAvgPool3D()(x)\n",
        "    else:\n",
        "        *_, f = x.get_shape().as_list()\n",
        "        x = Conv3D(f // compression, kernel_size=(1, 1, 1), padding='same', use_bias=True,\n",
        "                   kernel_initializer=kernel_initializer,\n",
        "                   kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "        x = AveragePooling3D((2, 2, 2), padding='valid')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_model(weights=None, verbose=True, **kwargs):\n",
        "    for k, v in kwargs.items():\n",
        "        assert k in PARAMS\n",
        "        PARAMS[k] = v\n",
        "    if verbose:\n",
        "        print(\"Model hyper-parameters:\", PARAMS)\n",
        "\n",
        "    dhw = PARAMS['dhw']\n",
        "    first_scale = PARAMS['first_scale']\n",
        "    first_layer = PARAMS['first_layer']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    down_structure = PARAMS['down_structure']\n",
        "    output_size = PARAMS['output_size']\n",
        "\n",
        "    shape = dhw + [1]\n",
        "\n",
        "    inputs = Input(shape=shape)\n",
        "\n",
        "    if first_scale is not None:\n",
        "        scaled = Lambda(first_scale)(inputs)\n",
        "    else:\n",
        "        scaled = inputs\n",
        "    conv = Conv3D(first_layer, kernel_size=(3, 3, 3), padding='same', use_bias=True,\n",
        "                  kernel_initializer=kernel_initializer,\n",
        "                  kernel_regularizer=l2_penalty(weight_decay))(scaled)\n",
        "\n",
        "    downsample_times = len(down_structure)\n",
        "    top_down = []\n",
        "    for l, n in enumerate(down_structure):\n",
        "        db = _dense_block(conv, n)\n",
        "        top_down.append(db)\n",
        "        conv = _transmit_block(db, l == downsample_times - 1)\n",
        "\n",
        "    feat = top_down[-1]\n",
        "    for top_feat in reversed(top_down[:-1]):\n",
        "        *_, f = top_feat.get_shape().as_list()\n",
        "        deconv = Conv3DTranspose(filters=f, kernel_size=2, strides=2, use_bias=True,\n",
        "                                 kernel_initializer=kernel_initializer,\n",
        "                                 kernel_regularizer=l2_penalty(weight_decay))(feat)\n",
        "        feat = add([top_feat, deconv])\n",
        "    seg_head = Conv3D(1, kernel_size=(1, 1, 1), padding='same',\n",
        "                      activation='sigmoid', use_bias=True,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=l2_penalty(weight_decay),\n",
        "                      name='seg')(feat)\n",
        "\n",
        "    if output_size == 1:\n",
        "        last_activation = 'sigmoid'\n",
        "    else:\n",
        "        last_activation = 'softmax'\n",
        "\n",
        "    clf_head = Dense(output_size, activation=last_activation,\n",
        "                     kernel_regularizer=l2_penalty(weight_decay),\n",
        "                     kernel_initializer=kernel_initializer,\n",
        "                     name='clf')(conv)\n",
        "\n",
        "    model = Model(inputs, [clf_head, seg_head])\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "class DiceLoss:\n",
        "    def __init__(self, beta=1., smooth=1.):\n",
        "        self.__name__ = 'dice_loss_' + str(int(beta * 100))\n",
        "        self.beta = beta  # the more beta, the more recall\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        bb = self.beta * self.beta\n",
        "        y_true_f = K.batch_flatten(y_true)\n",
        "        y_pred_f = K.batch_flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f, axis=-1)\n",
        "        weighted_union = bb * K.sum(y_true_f, axis=-1) + \\\n",
        "                         K.sum(y_pred_f, axis=-1)\n",
        "        score = -((1 + bb) * intersection + self.smooth) / \\\n",
        "                (weighted_union + self.smooth)\n",
        "        return score\n",
        "\n",
        "from mylib.model import metrics\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer=Adam(lr=learning_rate),\n",
        "              loss={\"clf\": 'binary_crossentropy',\n",
        "                    \"seg\": DiceLoss()},\n",
        "              metrics={'clf': ['accuracy',metrics.auc],'seg': 'accuracy'},\n",
        "              loss_weights={\"clf\": 1., \"seg\": .2})\n",
        "    \n",
        "checkpointer = ModelCheckpoint(filepath='tmp/%s/weights.{epoch:02d}.h5' % save_folder, verbose=1,\n",
        "                                   period=1, save_weights_only=True)\n",
        "best_keeper = ModelCheckpoint(filepath='tmp/%s/best.h5' % save_folder, verbose=1, save_weights_only=True,\n",
        "                                  monitor='val_clf_auc', save_best_only=True, period=1, mode='max')\n",
        "csv_logger = CSVLogger('tmp/%s/training.csv' % save_folder)\n",
        "tensorboard = TensorBoard(log_dir='tmp/%s/logs/' % save_folder)\n",
        "early_stopping = EarlyStopping(monitor='val_clf_acc', min_delta=0, mode='max',\n",
        "                                   patience=40, verbose=1)\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.334, patience=10,\n",
        "                                   verbose=1, mode='min', epsilon=1.e-5, cooldown=2, min_lr=0)\n",
        "model.fit_generator(generator=train_loader, steps_per_epoch=20, max_queue_size=500, workers=1,\n",
        "                        validation_data=val_loader, epochs=epochs, validation_steps=15,\n",
        "                        callbacks=[checkpointer, early_stopping, best_keeper, lr_reducer, csv_logger, tensorboard])\n",
        "\n",
        "\n",
        "#test_data=next(test_loader)\n",
        "#print(test_data.shape)\n",
        "#b=model.predict(test_data)\n",
        "#result['Score']=b[0]\n",
        "#save=pd.DataFrame(data=result)\n",
        "#save.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model hyper-parameters: {'activation': <function <lambda> at 0x7fd2ebf7fd08>, 'bn_scale': True, 'weight_decay': 0.0, 'kernel_initializer': 'he_uniform', 'first_scale': <function <lambda> at 0x7fd2ebf7fd90>, 'dhw': [32, 32, 32], 'k': 16, 'bottleneck': 4, 'compression': 2, 'first_layer': 32, 'down_structure': [4, 4, 4], 'output_size': 1, 'dropout_rate': None}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 32, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32, 32, 32, 1 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 32, 32, 32, 3 896         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32, 3 128         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 32, 32, 32, 6 2048        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32, 6 256         conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 32, 32, 32, 1 27664       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 32, 4 0           conv3d_3[0][0]                   \n",
            "                                                                 conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32, 4 192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32, 4 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 32, 32, 32, 6 3072        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32, 6 256         conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 32, 32, 32, 1 27664       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32, 6 0           conv3d_5[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32, 6 256         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 32, 32, 32, 6 4096        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32, 6 256         conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 32, 32, 32, 1 27664       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 32, 8 0           conv3d_7[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32, 8 320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 32, 8 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 32, 32, 32, 6 5120        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32, 6 256         conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 32, 32, 32, 1 27664       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 32, 9 0           conv3d_9[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 32, 9 384         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32, 9 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 32, 32, 32, 4 4656        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_1 (AveragePoo (None, 16, 16, 16, 4 0           conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 16, 4 192         average_pooling3d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 16, 4 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 16, 16, 16, 6 3072        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 16, 6 256         conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 16, 6 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 16, 16, 16, 1 27664       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 16, 6 0           conv3d_12[0][0]                  \n",
            "                                                                 average_pooling3d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 16, 6 256         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 16, 6 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 16, 16, 16, 6 4096        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 16, 6 256         conv3d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 16, 6 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_14 (Conv3D)              (None, 16, 16, 16, 1 27664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 16, 8 0           conv3d_14[0][0]                  \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 16, 8 320         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 16, 8 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_15 (Conv3D)              (None, 16, 16, 16, 6 5120        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 16, 6 256         conv3d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 16, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_16 (Conv3D)              (None, 16, 16, 16, 1 27664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 16, 9 0           conv3d_16[0][0]                  \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 16, 9 384         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 16, 9 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_17 (Conv3D)              (None, 16, 16, 16, 6 6144        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 16, 6 256         conv3d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 16, 6 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_18 (Conv3D)              (None, 16, 16, 16, 1 27664       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 16, 1 0           conv3d_18[0][0]                  \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 16, 1 448         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 16, 1 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_19 (Conv3D)              (None, 16, 16, 16, 5 6328        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_2 (AveragePoo (None, 8, 8, 8, 56)  0           conv3d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 8, 56)  224         average_pooling3d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 8, 56)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_20 (Conv3D)              (None, 8, 8, 8, 64)  3584        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 8, 64)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_21 (Conv3D)              (None, 8, 8, 8, 16)  27664       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 8, 8, 8, 72)  0           conv3d_21[0][0]                  \n",
            "                                                                 average_pooling3d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 8, 72)  288         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 8, 72)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_22 (Conv3D)              (None, 8, 8, 8, 64)  4608        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 8, 64)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_23 (Conv3D)              (None, 8, 8, 8, 16)  27664       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 8, 88)  0           conv3d_23[0][0]                  \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 8, 88)  352         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 8, 88)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_24 (Conv3D)              (None, 8, 8, 8, 64)  5632        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 8, 64)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_25 (Conv3D)              (None, 8, 8, 8, 16)  27664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 8, 8, 8, 104) 0           conv3d_25[0][0]                  \n",
            "                                                                 concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 8, 104) 416         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 8, 104) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_26 (Conv3D)              (None, 8, 8, 8, 64)  6656        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 8, 64)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_27 (Conv3D)              (None, 8, 8, 8, 16)  27664       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 8, 8, 8, 120) 0           conv3d_27[0][0]                  \n",
            "                                                                 concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_1 (Conv3DTrans (None, 16, 16, 16, 1 107632      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 8, 120) 480         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 16, 1 0           concatenate_8[0][0]              \n",
            "                                                                 conv3d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 8, 120) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_2 (Conv3DTrans (None, 32, 32, 32, 9 86112       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_1 (Glo (None, 120)          0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 32, 9 0           concatenate_4[0][0]              \n",
            "                                                                 conv3d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "clf (Dense)                     (None, 1)            121         global_average_pooling3d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "seg (Conv3D)                    (None, 32, 32, 32, 1 97          add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 598,770\n",
            "Trainable params: 594,914\n",
            "Non-trainable params: 3,856\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/mylib/model/metrics.py:5: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/mylib/model/metrics.py:6: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/100\n",
            "Size 50\n",
            "Size 415\n",
            "20/20 [==============================] - 268s 13s/step - loss: 0.5121 - clf_loss: 0.6546 - seg_loss: -0.7125 - clf_acc: 0.6350 - clf_auc: 0.6334 - seg_acc: 0.9605 - val_loss: 3.4623 - val_clf_loss: 3.5626 - val_seg_loss: -0.5016 - val_clf_acc: 0.5000 - val_clf_auc: 0.6333 - val_seg_acc: 0.9230\n",
            "\n",
            "Epoch 00001: saving model to tmp/test/weights.01.h5\n",
            "\n",
            "Epoch 00001: val_clf_auc improved from -inf to 0.63328, saving model to tmp/test/best.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 0.4644 - clf_loss: 0.6489 - seg_loss: -0.9221 - clf_acc: 0.6500 - clf_auc: 0.6262 - seg_acc: 0.9904 - val_loss: 1.2017 - val_clf_loss: 1.2897 - val_seg_loss: -0.4403 - val_clf_acc: 0.5200 - val_clf_auc: 0.6229 - val_seg_acc: 0.9090\n",
            "\n",
            "Epoch 00002: saving model to tmp/test/weights.02.h5\n",
            "\n",
            "Epoch 00002: val_clf_auc did not improve from 0.63328\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 0.4210 - clf_loss: 0.6117 - seg_loss: -0.9537 - clf_acc: 0.6850 - clf_auc: 0.6285 - seg_acc: 0.9939 - val_loss: 2.6576 - val_clf_loss: 2.7726 - val_seg_loss: -0.5746 - val_clf_acc: 0.5000 - val_clf_auc: 0.6290 - val_seg_acc: 0.9575\n",
            "\n",
            "Epoch 00003: saving model to tmp/test/weights.03.h5\n",
            "\n",
            "Epoch 00003: val_clf_auc did not improve from 0.63328\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 0.4341 - clf_loss: 0.6278 - seg_loss: -0.9687 - clf_acc: 0.6567 - clf_auc: 0.6284 - seg_acc: 0.9962 - val_loss: 0.7940 - val_clf_loss: 0.9872 - val_seg_loss: -0.9656 - val_clf_acc: 0.4200 - val_clf_auc: 0.6306 - val_seg_acc: 0.9956\n",
            "\n",
            "Epoch 00004: saving model to tmp/test/weights.04.h5\n",
            "\n",
            "Epoch 00004: val_clf_auc did not improve from 0.63328\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 0.4109 - clf_loss: 0.6059 - seg_loss: -0.9749 - clf_acc: 0.6817 - clf_auc: 0.6359 - seg_acc: 0.9968 - val_loss: 1.2054 - val_clf_loss: 1.3851 - val_seg_loss: -0.8984 - val_clf_acc: 0.5000 - val_clf_auc: 0.6359 - val_seg_acc: 0.9810\n",
            "\n",
            "Epoch 00005: saving model to tmp/test/weights.05.h5\n",
            "\n",
            "Epoch 00005: val_clf_auc improved from 0.63328 to 0.63593, saving model to tmp/test/best.h5\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 0.4130 - clf_loss: 0.6083 - seg_loss: -0.9762 - clf_acc: 0.6750 - clf_auc: 0.6373 - seg_acc: 0.9969 - val_loss: 0.7054 - val_clf_loss: 0.8972 - val_seg_loss: -0.9593 - val_clf_acc: 0.4400 - val_clf_auc: 0.6391 - val_seg_acc: 0.9975\n",
            "\n",
            "Epoch 00006: saving model to tmp/test/weights.06.h5\n",
            "\n",
            "Epoch 00006: val_clf_auc improved from 0.63593 to 0.63905, saving model to tmp/test/best.h5\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.4094 - clf_loss: 0.6058 - seg_loss: -0.9820 - clf_acc: 0.6950 - clf_auc: 0.6436 - seg_acc: 0.9974 - val_loss: 4.0158 - val_clf_loss: 4.0785 - val_seg_loss: -0.3134 - val_clf_acc: 0.5000 - val_clf_auc: 0.6419 - val_seg_acc: 0.7926\n",
            "\n",
            "Epoch 00007: saving model to tmp/test/weights.07.h5\n",
            "\n",
            "Epoch 00007: val_clf_auc improved from 0.63905 to 0.64190, saving model to tmp/test/best.h5\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 0.3981 - clf_loss: 0.5944 - seg_loss: -0.9817 - clf_acc: 0.6633 - clf_auc: 0.6427 - seg_acc: 0.9978 - val_loss: 4.4236 - val_clf_loss: 4.5430 - val_seg_loss: -0.5971 - val_clf_acc: 0.5000 - val_clf_auc: 0.6435 - val_seg_acc: 0.9230\n",
            "\n",
            "Epoch 00008: saving model to tmp/test/weights.08.h5\n",
            "\n",
            "Epoch 00008: val_clf_auc improved from 0.64190 to 0.64351, saving model to tmp/test/best.h5\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 13s 642ms/step - loss: 0.3992 - clf_loss: 0.5959 - seg_loss: -0.9836 - clf_acc: 0.6917 - clf_auc: 0.6435 - seg_acc: 0.9973 - val_loss: 4.4384 - val_clf_loss: 4.4935 - val_seg_loss: -0.2756 - val_clf_acc: 0.3800 - val_clf_auc: 0.6419 - val_seg_acc: 0.5886\n",
            "\n",
            "Epoch 00009: saving model to tmp/test/weights.09.h5\n",
            "\n",
            "Epoch 00009: val_clf_auc did not improve from 0.64351\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 13s 642ms/step - loss: 0.3833 - clf_loss: 0.5811 - seg_loss: -0.9888 - clf_acc: 0.7050 - clf_auc: 0.6413 - seg_acc: 0.9980 - val_loss: 5.1881 - val_clf_loss: 5.2375 - val_seg_loss: -0.2470 - val_clf_acc: 0.4000 - val_clf_auc: 0.6406 - val_seg_acc: 0.5530\n",
            "\n",
            "Epoch 00010: saving model to tmp/test/weights.10.h5\n",
            "\n",
            "Epoch 00010: val_clf_auc did not improve from 0.64351\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 13s 642ms/step - loss: 0.3735 - clf_loss: 0.5718 - seg_loss: -0.9912 - clf_acc: 0.7100 - clf_auc: 0.6409 - seg_acc: 0.9984 - val_loss: 1.6561 - val_clf_loss: 1.7097 - val_seg_loss: -0.2679 - val_clf_acc: 0.5200 - val_clf_auc: 0.6438 - val_seg_acc: 0.6621\n",
            "\n",
            "Epoch 00011: saving model to tmp/test/weights.11.h5\n",
            "\n",
            "Epoch 00011: val_clf_auc improved from 0.64351 to 0.64385, saving model to tmp/test/best.h5\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.3870 - clf_loss: 0.5853 - seg_loss: -0.9913 - clf_acc: 0.6833 - clf_auc: 0.6466 - seg_acc: 0.9984 - val_loss: 1.2038 - val_clf_loss: 1.2798 - val_seg_loss: -0.3801 - val_clf_acc: 0.5200 - val_clf_auc: 0.6471 - val_seg_acc: 0.9172\n",
            "\n",
            "Epoch 00012: saving model to tmp/test/weights.12.h5\n",
            "\n",
            "Epoch 00012: val_clf_auc improved from 0.64385 to 0.64708, saving model to tmp/test/best.h5\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.3651 - clf_loss: 0.5630 - seg_loss: -0.9894 - clf_acc: 0.7167 - clf_auc: 0.6495 - seg_acc: 0.9980 - val_loss: 1.8155 - val_clf_loss: 1.9021 - val_seg_loss: -0.4330 - val_clf_acc: 0.5400 - val_clf_auc: 0.6512 - val_seg_acc: 0.9568\n",
            "\n",
            "Epoch 00013: saving model to tmp/test/weights.13.h5\n",
            "\n",
            "Epoch 00013: val_clf_auc improved from 0.64708 to 0.65122, saving model to tmp/test/best.h5\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.3697 - clf_loss: 0.5678 - seg_loss: -0.9906 - clf_acc: 0.6950 - clf_auc: 0.6538 - seg_acc: 0.9983 - val_loss: 2.7060 - val_clf_loss: 2.7639 - val_seg_loss: -0.2895 - val_clf_acc: 0.5200 - val_clf_auc: 0.6537 - val_seg_acc: 0.7095\n",
            "\n",
            "Epoch 00014: saving model to tmp/test/weights.14.h5\n",
            "\n",
            "Epoch 00014: val_clf_auc improved from 0.65122 to 0.65368, saving model to tmp/test/best.h5\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.3855 - clf_loss: 0.5840 - seg_loss: -0.9927 - clf_acc: 0.6933 - clf_auc: 0.6547 - seg_acc: 0.9985 - val_loss: 5.9878 - val_clf_loss: 6.0561 - val_seg_loss: -0.3418 - val_clf_acc: 0.5400 - val_clf_auc: 0.6547 - val_seg_acc: 0.8262\n",
            "\n",
            "Epoch 00015: saving model to tmp/test/weights.15.h5\n",
            "\n",
            "Epoch 00015: val_clf_auc improved from 0.65368 to 0.65474, saving model to tmp/test/best.h5\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.3411 - clf_loss: 0.5394 - seg_loss: -0.9916 - clf_acc: 0.7283 - clf_auc: 0.6567 - seg_acc: 0.9981 - val_loss: 0.9815 - val_clf_loss: 1.0459 - val_seg_loss: -0.3217 - val_clf_acc: 0.5200 - val_clf_auc: 0.6586 - val_seg_acc: 0.7508\n",
            "\n",
            "Epoch 00016: saving model to tmp/test/weights.16.h5\n",
            "\n",
            "Epoch 00016: val_clf_auc improved from 0.65474 to 0.65857, saving model to tmp/test/best.h5\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00033400001586414874.\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.3249 - clf_loss: 0.5236 - seg_loss: -0.9936 - clf_acc: 0.7417 - clf_auc: 0.6612 - seg_acc: 0.9988 - val_loss: 4.0706 - val_clf_loss: 4.1227 - val_seg_loss: -0.2602 - val_clf_acc: 0.5000 - val_clf_auc: 0.6625 - val_seg_acc: 0.6025\n",
            "\n",
            "Epoch 00017: saving model to tmp/test/weights.17.h5\n",
            "\n",
            "Epoch 00017: val_clf_auc improved from 0.65857 to 0.66254, saving model to tmp/test/best.h5\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.2880 - clf_loss: 0.4868 - seg_loss: -0.9940 - clf_acc: 0.7717 - clf_auc: 0.6650 - seg_acc: 0.9984 - val_loss: 1.0806 - val_clf_loss: 1.1598 - val_seg_loss: -0.3961 - val_clf_acc: 0.5000 - val_clf_auc: 0.6675 - val_seg_acc: 0.9229\n",
            "\n",
            "Epoch 00018: saving model to tmp/test/weights.18.h5\n",
            "\n",
            "Epoch 00018: val_clf_auc improved from 0.66254 to 0.66753, saving model to tmp/test/best.h5\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 13s 635ms/step - loss: 0.2707 - clf_loss: 0.4695 - seg_loss: -0.9944 - clf_acc: 0.7883 - clf_auc: 0.6709 - seg_acc: 0.9986 - val_loss: 0.9069 - val_clf_loss: 0.9703 - val_seg_loss: -0.3169 - val_clf_acc: 0.5600 - val_clf_auc: 0.6737 - val_seg_acc: 0.7502\n",
            "\n",
            "Epoch 00019: saving model to tmp/test/weights.19.h5\n",
            "\n",
            "Epoch 00019: val_clf_auc improved from 0.66753 to 0.67367, saving model to tmp/test/best.h5\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.2691 - clf_loss: 0.4681 - seg_loss: -0.9951 - clf_acc: 0.7617 - clf_auc: 0.6772 - seg_acc: 0.9990 - val_loss: 1.3531 - val_clf_loss: 1.4878 - val_seg_loss: -0.6734 - val_clf_acc: 0.5400 - val_clf_auc: 0.6793 - val_seg_acc: 0.9902\n",
            "\n",
            "Epoch 00020: saving model to tmp/test/weights.20.h5\n",
            "\n",
            "Epoch 00020: val_clf_auc improved from 0.67367 to 0.67932, saving model to tmp/test/best.h5\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.2484 - clf_loss: 0.4472 - seg_loss: -0.9942 - clf_acc: 0.7917 - clf_auc: 0.6822 - seg_acc: 0.9987 - val_loss: 2.0711 - val_clf_loss: 2.1651 - val_seg_loss: -0.4699 - val_clf_acc: 0.5000 - val_clf_auc: 0.6839 - val_seg_acc: 0.9753\n",
            "\n",
            "Epoch 00021: saving model to tmp/test/weights.21.h5\n",
            "\n",
            "Epoch 00021: val_clf_auc improved from 0.67932 to 0.68388, saving model to tmp/test/best.h5\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 13s 637ms/step - loss: 0.2031 - clf_loss: 0.4019 - seg_loss: -0.9938 - clf_acc: 0.8217 - clf_auc: 0.6866 - seg_acc: 0.9986 - val_loss: 4.4462 - val_clf_loss: 4.5009 - val_seg_loss: -0.2735 - val_clf_acc: 0.5000 - val_clf_auc: 0.6886 - val_seg_acc: 0.6191\n",
            "\n",
            "Epoch 00022: saving model to tmp/test/weights.22.h5\n",
            "\n",
            "Epoch 00022: val_clf_auc improved from 0.68388 to 0.68862, saving model to tmp/test/best.h5\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 0.2195 - clf_loss: 0.4183 - seg_loss: -0.9940 - clf_acc: 0.8283 - clf_auc: 0.6906 - seg_acc: 0.9986 - val_loss: 3.9374 - val_clf_loss: 4.0110 - val_seg_loss: -0.3684 - val_clf_acc: 0.5000 - val_clf_auc: 0.6926 - val_seg_acc: 0.8136\n",
            "\n",
            "Epoch 00023: saving model to tmp/test/weights.23.h5\n",
            "\n",
            "Epoch 00023: val_clf_auc improved from 0.68862 to 0.69262, saving model to tmp/test/best.h5\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 13s 642ms/step - loss: 0.1859 - clf_loss: 0.3846 - seg_loss: -0.9937 - clf_acc: 0.8333 - clf_auc: 0.6951 - seg_acc: 0.9988 - val_loss: 4.2139 - val_clf_loss: 4.3570 - val_seg_loss: -0.7157 - val_clf_acc: 0.5000 - val_clf_auc: 0.6968 - val_seg_acc: 0.9955\n",
            "\n",
            "Epoch 00024: saving model to tmp/test/weights.24.h5\n",
            "\n",
            "Epoch 00024: val_clf_auc improved from 0.69262 to 0.69683, saving model to tmp/test/best.h5\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 0.1455 - clf_loss: 0.3442 - seg_loss: -0.9932 - clf_acc: 0.8567 - clf_auc: 0.6995 - seg_acc: 0.9984 - val_loss: 4.5509 - val_clf_loss: 4.6279 - val_seg_loss: -0.3852 - val_clf_acc: 0.5000 - val_clf_auc: 0.7018 - val_seg_acc: 0.8396\n",
            "\n",
            "Epoch 00025: saving model to tmp/test/weights.25.h5\n",
            "\n",
            "Epoch 00025: val_clf_auc improved from 0.69683 to 0.70177, saving model to tmp/test/best.h5\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 13s 639ms/step - loss: 0.1107 - clf_loss: 0.3095 - seg_loss: -0.9939 - clf_acc: 0.8900 - clf_auc: 0.7049 - seg_acc: 0.9985 - val_loss: 4.0808 - val_clf_loss: 4.2341 - val_seg_loss: -0.7664 - val_clf_acc: 0.5000 - val_clf_auc: 0.7074 - val_seg_acc: 0.9953\n",
            "\n",
            "Epoch 00026: saving model to tmp/test/weights.26.h5\n",
            "\n",
            "Epoch 00026: val_clf_auc improved from 0.70177 to 0.70744, saving model to tmp/test/best.h5\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 13s 639ms/step - loss: 0.1057 - clf_loss: 0.3046 - seg_loss: -0.9941 - clf_acc: 0.8817 - clf_auc: 0.7099 - seg_acc: 0.9986 - val_loss: 5.8978 - val_clf_loss: 6.0128 - val_seg_loss: -0.5750 - val_clf_acc: 0.5000 - val_clf_auc: 0.7121 - val_seg_acc: 0.9776\n",
            "\n",
            "Epoch 00027: saving model to tmp/test/weights.27.h5\n",
            "\n",
            "Epoch 00027: val_clf_auc improved from 0.70744 to 0.71214, saving model to tmp/test/best.h5\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00011155600374331699.\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 0.0592 - clf_loss: 0.2581 - seg_loss: -0.9945 - clf_acc: 0.9083 - clf_auc: 0.7152 - seg_acc: 0.9985 - val_loss: 4.4882 - val_clf_loss: 4.5996 - val_seg_loss: -0.5570 - val_clf_acc: 0.5000 - val_clf_auc: 0.7175 - val_seg_acc: 0.9732\n",
            "\n",
            "Epoch 00028: saving model to tmp/test/weights.28.h5\n",
            "\n",
            "Epoch 00028: val_clf_auc improved from 0.71214 to 0.71753, saving model to tmp/test/best.h5\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.0069 - clf_loss: 0.2059 - seg_loss: -0.9947 - clf_acc: 0.9550 - clf_auc: 0.7210 - seg_acc: 0.9989 - val_loss: 4.0029 - val_clf_loss: 4.1312 - val_seg_loss: -0.6414 - val_clf_acc: 0.5000 - val_clf_auc: 0.7235 - val_seg_acc: 0.9888\n",
            "\n",
            "Epoch 00029: saving model to tmp/test/weights.29.h5\n",
            "\n",
            "Epoch 00029: val_clf_auc improved from 0.71753 to 0.72354, saving model to tmp/test/best.h5\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.0032 - clf_loss: 0.2021 - seg_loss: -0.9946 - clf_acc: 0.9500 - clf_auc: 0.7266 - seg_acc: 0.9986 - val_loss: 3.8521 - val_clf_loss: 3.9855 - val_seg_loss: -0.6670 - val_clf_acc: 0.5000 - val_clf_auc: 0.7289 - val_seg_acc: 0.9914\n",
            "\n",
            "Epoch 00030: saving model to tmp/test/weights.30.h5\n",
            "\n",
            "Epoch 00030: val_clf_auc improved from 0.72354 to 0.72895, saving model to tmp/test/best.h5\n",
            "Epoch 31/100\n",
            " 5/20 [======>.......................] - ETA: 8s - loss: -0.0234 - clf_loss: 0.1756 - seg_loss: -0.9952 - clf_acc: 0.9667 - clf_auc: 0.7288 - seg_acc: 0.9988"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoMCqf1k84jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download('result.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
